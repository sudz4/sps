{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmgus.ipynb\n",
    "\"Pre-Market Gap-Up Screener\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# show all pandas row width\n",
    "pd.set_option('display.max_rows', None)\n",
    "# show all pandas column width\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #0 - DATA IMPORT |\n",
    "|-|\n",
    "| file import setup |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/tv_screen_gap-up_2024-11-05.csv\n",
      "1490\n",
      "0     NVDA\n",
      "1     MSFT\n",
      "2    GOOGL\n",
      "3     GOOG\n",
      "4     AMZN\n",
      "Name: Symbol, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# base file path and file path setup\n",
    "base_dir_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/' \n",
    "std_file_name_str = 'tv_screen_gap-up_'\n",
    "\n",
    "#####---------------------#####\n",
    "screen_date = '2024-11-05' # 72\n",
    "# screen_date = '2024-11-07' # 181 L1\n",
    "# screen_date = '2024-11-08' # 45 L1\n",
    "#####---------------------#####\n",
    "\n",
    "file_type = '.csv'\n",
    "filename = base_dir_path + std_file_name_str + screen_date + file_type\n",
    "\n",
    "# read the csv file\n",
    "print(filename)\n",
    "trading_view_df = pd.read_csv(filename)\n",
    "print(len(trading_view_df))\n",
    "# print first 5 ticker Symbols only\n",
    "print(trading_view_df['Symbol'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #1 - SCREENER |\n",
    "|-|\n",
    "| xxx |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 stockes found in the screener.\n"
     ]
    }
   ],
   "source": [
    "def categorize_market_cap(df):\n",
    "    \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "    df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "    conditions = [\n",
    "        (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "        (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "        (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "        (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "        (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "        (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "    ]\n",
    "    categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "    df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "    return df\n",
    "\n",
    "# execute categorization\n",
    "category_setup_df = categorize_market_cap(trading_view_df).copy()\n",
    "\n",
    "# drop Undefined marketCapType\n",
    "category_setup_df = category_setup_df[category_setup_df['marketCapType'] != 'Undefined']\n",
    "\n",
    "# convert necessary columns to numeric\n",
    "def convert_columns_to_numeric(df, columns):\n",
    "    \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# list of columns to convert\n",
    "numeric_columns = [\n",
    "    'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "    'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "    'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "    'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "]\n",
    "\n",
    "# Apply conversion\n",
    "category_setup_df = convert_columns_to_numeric(category_setup_df, numeric_columns)\n",
    "\n",
    "# Criteria configuration for each market cap category\n",
    "criteria_config = {\n",
    "    \"Titans\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "        \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.03,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Large caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "        \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "        \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "        \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "        \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    # \"Midlers\" in TradingView\n",
    "    \"Midlers\": { \n",
    "        \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "        \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "        \"relative_volume_threshold\": 1.3,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Small caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "        \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Micro caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "        \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "        \"relative_volume_threshold\": 1.1,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Shrimp\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "        \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "        \"relative_volume_threshold\": 1.0,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    }\n",
    "}\n",
    "\n",
    "def filter_stocks(df, config):\n",
    "    \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "    conditions = (\n",
    "        (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "        (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "        (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "        (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "        (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "        (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "        (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "    )\n",
    "    return df[conditions]\n",
    "\n",
    "def screen_stocks_by_category(df, category):\n",
    "    \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "    config = criteria_config.get(category, {})\n",
    "    filtered_df = filter_stocks(df, config)\n",
    "    return filtered_df\n",
    "\n",
    "# execute filtering\n",
    "smash_df = pd.DataFrame()\n",
    "categories = category_setup_df['marketCapType'].unique()\n",
    "\n",
    "for category in categories:\n",
    "    category_df = category_setup_df[category_setup_df['marketCapType'] == category]\n",
    "    gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "    smash_df = pd.concat([smash_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# add 'Market capitalization' to the reordered columns list\n",
    "cols_list = [\n",
    "    'Symbol', \n",
    "    'Description', \n",
    "    'marketCapType', \n",
    "    'Pre-market Change %', \n",
    "    'Pre-market Gap %', \n",
    "    'marketCapType',\n",
    "    'Market capitalization',\n",
    "    'Price', \n",
    "    'Pre-market Open', \n",
    "    'Industry', \n",
    "    'Index', \n",
    "    'Sector', \n",
    "    'Exchange',\n",
    "    'Recent earnings date', \n",
    "    'Upcoming earnings date', \n",
    "    'Float shares outstanding', \n",
    "    'Average Volume 10 days',\n",
    "    'Average Volume 30 days', \n",
    "    'Average Volume 90 days',\n",
    "    'Relative Volume 1 day', \n",
    "    'Relative Volume 5 minutes', \n",
    "    'Relative Volume 30 minutes', \n",
    "    'Relative Volume at Time', \n",
    "    'Analyst Rating'\n",
    "]\n",
    "\n",
    "# filter columns to only include those present in the DataFrame\n",
    "existing_cols = [col for col in cols_list if col in smash_df.columns]\n",
    "smash_df = smash_df[existing_cols]\n",
    "\n",
    "# sort and reset index\n",
    "smash_df = smash_df.sort_values(\n",
    "    by=['Pre-market Change %', 'Price'],\n",
    "    ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(f\"{smash_df.shape[0]} stockes found in the screener.\")\n",
    "# ## ISSUE ##\n",
    "# #### HARD CODED FILE PATH ####\n",
    "# # also change this if you add another level, you probably will to screener_smoke \n",
    "# # output_filename = f'pre_market_gap_up_screener_targets_{today_date_str}.csv'\n",
    "# output_filename = f'/Users/sudz4/Desktop/BOOK-II/nowbear/stgy_pm-gap-up-screener/data_pmgus/output_pmgus/pre_market_gap_up_screener_targets_2024-09-26.csv'\n",
    "\n",
    "# smash_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(smash_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "72\n",
      "['ALAB', 'DUO', 'INTA', 'AZPN', 'JANX', 'TWST', 'RYTM', 'RNW', 'AS', 'IESC', 'PSNY', 'MLTX', 'FTDR', 'RIOT', 'VRNA', 'CLS', 'CLOV', 'FRPT', 'VCYT', 'MDU', 'EWTX', 'COMP', 'LNTH', 'IBTA', 'TAL', 'WWD', 'APA', 'RLX', 'MTDR', 'ARWR', 'GERN', 'CLBT', 'GTLS', 'AUR', 'VFS', 'SLG', 'WFRD', 'DEI', 'BRZE', 'PTGX', 'BBIO', 'G', 'OLLI', 'ORA', 'ANF', 'WVE', 'EAT', 'MC', 'FLG', 'YETI', 'AR', 'MAC', 'IIPR', 'ASAN', 'HSIC', 'DORM', 'LAZ', 'HAFN', 'RCM', 'NXE', 'BBWI', 'FRSH', 'PK', 'CBU', 'VSH', 'ALKT', 'RDNT', 'KD', 'ROKU', 'TLN', 'QLYS', 'WDFC']\n"
     ]
    }
   ],
   "source": [
    "# return smash_list of Symbols\n",
    "smash_list = smash_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "print(len(smash_df))\n",
    "print(len(smash_list))\n",
    "print(smash_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #2 - SCREENER |\n",
    "|-|\n",
    "| TECHNICAL INDICATORS - via yahoo finance |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# from ta.trend import MACD\n",
    "# from ta.momentum import RSIIndicator\n",
    "# from ta.trend import SMAIndicator\n",
    "# from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "# from ta.trend import SMAIndicator, MACD, PSARIndicator\n",
    "# from ta.volatility import BollingerBands, AverageTrueRange\n",
    "# from ta.volume import OnBalanceVolumeIndicator\n",
    "# # import vectorbt as vbt\n",
    "# # vbt.settings.set_theme('dark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import SMAIndicator, MACD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add start date as a var for retroactive testing / backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_technical_indicators(df):\n",
    "    tech_data = []\n",
    "\n",
    "    for symbol in df['Symbol'].unique():\n",
    "        data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "        if not data.empty:\n",
    "            close_prices = data['Close'].squeeze()  # Ensure it's a 1-dimensional series\n",
    "            rsi = RSIIndicator(close_prices, window=14).rsi().iloc[-1] # last value!\n",
    "            ma20 = SMAIndicator(close_prices, window=20).sma_indicator().iloc[-1] # last value!\n",
    "            ma50 = SMAIndicator(close_prices, window=50).sma_indicator().iloc[-1] # last value!\n",
    "            macd = MACD(close_prices).macd_diff().iloc[-1] # last value!\n",
    "\n",
    "            tech_data.append({\n",
    "                'Symbol': symbol,\n",
    "                'RSI': rsi,\n",
    "                'MA20': ma20,\n",
    "                'MA50': ma50,\n",
    "                'MACD': macd,\n",
    "                'Yahoo Price': close_prices.iloc[-1], # last value! (price from Yahoo!)\n",
    "            })\n",
    "\n",
    "    tech_df = pd.DataFrame(tech_data)\n",
    "    return tech_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the last value because,\n",
    "technically for back testing you want to pay attention here.\n",
    "real time go time i think we want it most recent. meaning yesterday\n",
    "if we are making decisions and in pre-market trading hours based on the Close from yesterday\n",
    "yesterday = last Close $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 6)\n",
      "  Symbol        RSI        MA20       MA50      MACD  Yahoo Price\n",
      "0   ALAB  78.385988   74.644501   59.04600  2.463855    99.300003\n",
      "1    DUO  46.553244    1.154500    1.16538 -0.006209     1.080000\n",
      "2   INTA  80.280154   51.333500   48.55520  0.928593    59.389999\n",
      "3   AZPN  62.006543  238.450500  234.73580  0.563594   245.000000\n",
      "4   JANX  57.668318   53.008500   49.02180 -0.128566    53.919998\n"
     ]
    }
   ],
   "source": [
    "explode_df = compute_technical_indicators(smash_df)\n",
    "\n",
    "print(explode_df.shape)\n",
    "print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 6)\n",
      "  Symbol        RSI        MA20       MA50      MACD  Yahoo Price\n",
      "0   ALAB  78.385988   74.644501   59.04600  2.463855    99.300003\n",
      "1    DUO  46.553244    1.154500    1.16538 -0.006209     1.080000\n",
      "2   INTA  80.280154   51.333500   48.55520  0.928593    59.389999\n",
      "3   AZPN  62.006543  238.450500  234.73580  0.563594   245.000000\n",
      "4   JANX  57.668318   53.008500   49.02180 -0.128566    53.919998\n",
      "(72, 24)\n",
      "  Symbol                Description marketCapType\n",
      "0   ALAB          Astera Labs, Inc.    Large caps\n",
      "1    DUO  Fangdd Network Group Ltd.    Large caps\n",
      "2   INTA               Intapp, Inc.      Mid caps\n",
      "3   AZPN     Aspen Technology, Inc.    Large caps\n",
      "4   JANX   Janux Therapeutics, Inc.      Mid caps\n"
     ]
    }
   ],
   "source": [
    "print(explode_df.shape)\n",
    "print(explode_df.head())\n",
    "\n",
    "print(smash_df.shape)\n",
    "print(smash_df.iloc[:5,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_stocks_by_technical_indicators(df):\n",
    "    # filter based on RSI, MA, and MACD\n",
    "    df = df[(df['RSI'] >= 0) & (df['RSI'] < 70)]  # RSI filter condition\n",
    "    df = df[df['Yahoo Price'] > df['MA20']]\n",
    "    df = df[df['Yahoo Price'] > df['MA50']]\n",
    "    df = df[df['MACD'] > 0]\n",
    "    \"\"\" \n",
    "    # should i add more to this?\n",
    "    # level 3 will start to get more advanced filering\n",
    "    # dont want to overfilter to soon also and miss something\n",
    "    # patience\n",
    "    \"\"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "   Symbol        RSI        MA20        MA50      MACD  Yahoo Price\n",
      "3    AZPN  62.006543  238.450500  234.735800  0.563594   245.000000\n",
      "5    TWST  56.074022   43.668500   43.690800  0.409942    45.400002\n",
      "11   MLTX  60.179411   48.196500   49.350600  0.538137    51.779999\n",
      "18   VCYT  62.262657   34.416000   33.265500  0.285940    36.480000\n",
      "19    MDU  69.912946   16.275371   15.383057  0.139069    17.930000\n"
     ]
    }
   ],
   "source": [
    "explode_df = screen_stocks_by_technical_indicators(explode_df)\n",
    "\n",
    "print(len(explode_df))\n",
    "print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "\n",
      "24\n",
      "24\n",
      "['AZPN', 'TWST', 'MLTX', 'VCYT', 'MDU', 'COMP', 'MTDR', 'ARWR', 'CLBT', 'SLG', 'DEI', 'BRZE', 'BBIO', 'OLLI', 'ORA', 'MC', 'AR', 'MAC', 'LAZ', 'PK', 'CBU', 'RDNT', 'TLN', 'WDFC']\n"
     ]
    }
   ],
   "source": [
    "# return explode_list of Symbols\n",
    "explode_list = explode_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "print(len(smash_df))\n",
    "print()\n",
    "\n",
    "print(len(explode_df))\n",
    "print(len(explode_list))\n",
    "print(explode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-05\n"
     ]
    }
   ],
   "source": [
    "print(screen_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #3 - SCREENER |\n",
    "|-|\n",
    "| xxx |\n",
    "\n",
    "i think this is the place for those small tactical screeners\n",
    "maybe even think about deploying dynamically for instance one above this ta technical screener filter\n",
    "different days, different vols, and volatilty\n",
    "\n",
    "see index specific\n",
    "see vix\n",
    "companies in same industry, same sector, same location? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #4 - SCREENER |\n",
    "|-|\n",
    "| xxx |\n",
    "\n",
    "could think about doing additional available (but separate now) on the subset, additional technical indicators from ta library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "# from ta.trend import SMAIndicator, MACD, CCIIndicator\n",
    "# from ta.volatility import BollingerBands\n",
    "# from ta.volume import OnBalanceVolumeIndicator\n",
    "# from ta.volatility import AverageTrueRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_additional_indicators(df):\n",
    "#     additional_data = []\n",
    "\n",
    "#     for symbol in df['Symbol'].unique():\n",
    "#         data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "#         if not data.empty:\n",
    "#             close_prices = data['Close'].squeeze()  # Ensure it's a 1-dimensional series\n",
    "#             high_prices = data['High'].squeeze()\n",
    "#             low_prices = data['Low'].squeeze()\n",
    "#             volume = data['Volume'].squeeze()\n",
    "\n",
    "#             # Compute additional indicators\n",
    "#             bb = BollingerBands(close_prices)\n",
    "#             atr = AverageTrueRange(high=high_prices, low=low_prices, close=close_prices)\n",
    "#             stoch = StochasticOscillator(close=close_prices, high=high_prices, low=low_prices)\n",
    "#             obv = OnBalanceVolumeIndicator(close=close_prices, volume=volume)\n",
    "#             cci = CCIIndicator(high=high_prices, low=low_prices, close=close_prices)\n",
    "\n",
    "#             additional_data.append({\n",
    "#                 'Symbol': symbol,\n",
    "#                 'Bollinger High': bb.bollinger_hband().iloc[-1],\n",
    "#                 'Bollinger Low': bb.bollinger_lband().iloc[-1],\n",
    "#                 'ATR': atr.average_true_range().iloc[-1],\n",
    "#                 'Stochastic Oscillator': stoch.stoch().iloc[-1],\n",
    "#                 'OBV': obv.on_balance_volume().iloc[-1],\n",
    "#                 'CCI': cci.cci().iloc[-1],\n",
    "#             })\n",
    "\n",
    "#     additional_df = pd.DataFrame(additional_data)\n",
    "#     return additional_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_explode_df = compute_additional_indicators(explode_df)\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(len(double_explode_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_explode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_additional_indicators(df):\n",
    "#     # Example filter criteria\n",
    "#     filtered_df = df[\n",
    "#         (df['Stochastic Oscillator'] < 20) &  # Stochastic Oscillator indicates oversold\n",
    "#         (df['CCI'] < -100) &  # CCI indicates oversold\n",
    "#         (df['ATR'] > 1)  # ATR indicates high volatility\n",
    "#     ]\n",
    "#     return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_double_explode_df = filter_additional_indicators(double_explode_df)\n",
    "\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(len(filtered_double_explode_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #5,#6 - SCREENER |\n",
    "|-|\n",
    "| (mini) tight screeners - (toggle on and off w/comments?) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return index data for relevant?\n",
    "good time to see if that chart works opensource similar to tradingview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could also plot historical data for 53 stocks who cares. check it out on same chart?\n",
    "watch a youtube\n",
    "restart as new feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Notes |\n",
    "|-|\n",
    "| END of WORKING CODE |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data file from TradingView to pandas df\n",
    "# \"\"\" \n",
    "# Market : US\n",
    "# Exchange : NASDAQ, NYSE\n",
    "# Pre-market Chg > $0.00 USD\n",
    "\n",
    "# Stocks = ~1100\n",
    "# \"\"\"\n",
    "# base_file_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/'\n",
    "# file_name =  'tv_screen_gap-up_2024-10-29.csv'\n",
    "# pmgus_df = pd.read_csv(base_file_path + file_name)\n",
    "\n",
    "\n",
    "# print(len(pmgus_df))\n",
    "# pmgus_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_market_cap(df):\n",
    "#     \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "#     conditions = [\n",
    "#         (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "#         (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "#         (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "#         (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "#         (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "#         (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "#     ]\n",
    "#     categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "#     df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "#     # drop Undefined\n",
    "#     df = df[df['marketCapType'] != 'Undefined']\n",
    "#     # convert to numeric the Market capitalization column\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'])\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - categorize market cap\n",
    "# pmgus_df = categorize_market_cap(pmgus_df).copy()\n",
    "# print(len(pmgus_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert necessary columns to numeric\n",
    "# def convert_columns_to_numeric(df, columns):\n",
    "#     \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "#     for col in columns:\n",
    "#         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "#     return df\n",
    "\n",
    "# # list of columns to convert\n",
    "# numeric_columns = [\n",
    "#     'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "#     'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "#     'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "#     'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - convert columns to numeric\n",
    "# pmgus_df = convert_columns_to_numeric(pmgus_df, numeric_columns).copy()\n",
    "# print(len(pmgus_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria configuration for each market cap category\n",
    "# criteria_config = {\n",
    "#     \"Titans\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "#         \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.03,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "#         \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "#         \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     # \"Midlers\" in TradingView\n",
    "#     \"Midlers\": { \n",
    "#         \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "#         \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "#         \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "#         \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "#         \"relative_volume_threshold\": 1.1,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "#         \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "#         \"relative_volume_threshold\": 1.0,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_stocks(df, config):\n",
    "#     \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "#     conditions = (\n",
    "#         (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "#         (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "#         (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "#         (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "#         (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "#         (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "#         (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# def screen_stocks_by_category(df, category):\n",
    "#     \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "#     config = criteria_config.get(category, {})\n",
    "#     filtered_df = filter_stocks(df, config)\n",
    "#     return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for category in pmgus_df['marketCapType'].unique():\n",
    "#     category_df = pmgus_df[pmgus_df['marketCapType'] == category]\n",
    "#     gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "#     pmgus_two_df = pd.concat([category_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# print(len(pmgus_two_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enhanced volume screening -L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_cap_volume_thresholds = {\n",
    "#     \"Titans\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.001,  # 0.1% of ADV minimum in pre-market\n",
    "#         \"min_rel_vol_5min\": 1.5,        # 50% above normal 5-min volume\n",
    "#         \"min_rel_vol_15min\": 1.3        # 30% above normal 15-min volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.002,  # 0.2% of ADV\n",
    "#         \"min_rel_vol_5min\": 1.8,\n",
    "#         \"min_rel_vol_15min\": 1.5\n",
    "#     },\n",
    "#     \"Midlers\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.003,  # 0.3% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.0,\n",
    "#         \"min_rel_vol_15min\": 1.7\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.004,  # 0.4% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.5,\n",
    "#         \"min_rel_vol_15min\": 2.0\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.005,  # 0.5% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.0,\n",
    "#         \"min_rel_vol_15min\": 2.5\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.008,  # 0.8% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.5,\n",
    "#         \"min_rel_vol_15min\": 3.0\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# def analyze_premarket_volume_by_cap(df, conditions):\n",
    "#     \"\"\"\n",
    "#     Enhanced volume analysis based on market cap category with progressive thresholds\n",
    "#     \"\"\"\n",
    "#     df['PM_Volume_Ratio'] = df['Pre-market Volume'] / df['Average Volume 10 days']\n",
    "#     df['Volume_Acceleration'] = df['Relative Volume 5 minutes'] / df['Relative Volume 15 minutes']\n",
    "    \n",
    "#     # Apply filters based on market cap category\n",
    "#     conditions = []\n",
    "#     for cap_type, thresholds in market_cap_volume_thresholds.items():\n",
    "#         cap_condition = (\n",
    "#             (df['marketCapType'] == cap_type) &\n",
    "#             (df['PM_Volume_Ratio'] >= thresholds['min_pm_volume_vs_adv']) &\n",
    "#             (df['Relative Volume 5 minutes'] >= thresholds['min_rel_vol_5min']) &\n",
    "#             (df['Relative Volume 15 minutes'] >= thresholds['min_rel_vol_15min'])\n",
    "#         )\n",
    "#         conditions.append(cap_condition)\n",
    "    \n",
    "#     return pd.concat([df[cond] for cond in conditions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show all pandas row width\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# # show all pandas column width\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmgus_two_df = analyze_premarket_volume_by_cap(pmgus_two_df, market_cap_volume_thresholds)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))\n",
    "# display(pmgus_two_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# new_pmgus_df.to_csv(base_file_path + 'new_pmgus_2024-10-29_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))\n",
    "# print(len(pmgus_two_df.columns))\n",
    "# print(pmgus_two_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final L1 FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define no negatives\n",
    "# def no_negatives(df):\n",
    "#     \"\"\"Remove negative values in the data frame.\"\"\"\n",
    "#     return df[(df['Pre-market Change %'] >= 0) & (df['Pre-market Gap %'] >= 0)]\n",
    "\n",
    "# # apply no negatives\n",
    "# pmgus_two_df = no_negatives(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def technical_price_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter stocks based on their position relative to key technical levels\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price near recent highs suggesting momentum\n",
    "#         (df['Price'] >= df['High 1 month'] * 0.85) |  \n",
    "        \n",
    "#         # Price above all major SMAs showing strength\n",
    "#         (df['Price'] > df['Simple Moving Average (5) 1 minute']) &\n",
    "#         (df['Price'] > df['Simple Moving Average (13) 5 minutes']) &\n",
    "        \n",
    "#         # Price near upper Bollinger Band suggesting strength\n",
    "#         (df['Price'] >= df['Bollinger Bands (20) 5 minutes, Basis'])\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply technical price filter\n",
    "# pmgus_two_df = technical_price_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "might need to back off a little on the volatility filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fundamental_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter using analyst ratings and price targets\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price well below analyst targets suggesting upside\n",
    "#         (df['Target price 1 year'] > df['Price'] * 1.2) &\n",
    "        \n",
    "#         # Strong analyst ratings\n",
    "#         (df['Analyst Rating'].isin(['Strong buy', 'Buy']))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply fundamental filter\n",
    "# pmgus_two_df = fundamental_filter(pmgus_two_df)\n",
    "\n",
    "# # sort by change percentage descending\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def volatility_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter for stocks showing increasing volatility\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Increasing volatility pattern\n",
    "#         (df['Volatility 1 day'] > df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 week'] > df['Volatility 1 month']) &\n",
    "        \n",
    "#         # Beta filter for more responsive stocks\n",
    "#         (df['Beta 1 year'] > 1.0)\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply volatility filter\n",
    "# pmgus_two_df = volatility_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort by largest change percentage\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "# # look at data after initial filters\n",
    "# print(len(pmgus_two_df))\n",
    "# # display(pmgus_two_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # return symbol and price and analyst rating\n",
    "# pmgus_two_df[['Symbol', 'Price', 'Analyst Rating', 'marketCapType']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL GRANULAR FILTERS (when needed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want another volume one slightly more granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Price above short-term moving averages indicating immediate strength\n",
    "# price_conditions = (\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (5) 1 minute']) &\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (8) 1 minute'])\n",
    "# )\n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[price_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Volume additioal acceleration\n",
    "# vol_addtl_accel_conditions = (\n",
    "#     (pmgus_two_df['Relative Volume 1 minute'] > pmgus_two_df['Relative Volume 5 minutes']) &\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > 1.5)  &  # Strong recent volume\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > pmgus_two_df['Relative Volume 15 minutes']) &  # Accelerating volume\n",
    "#     (pmgus_two_df['Relative Volume 15 minutes'] > pmgus_two_df['Relative Volume 30 minutes'])) # building momentum \n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[vol_addtl_accel_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of additional filters when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open source tradingview type chart view. \n",
    "# then use historical data and plat the daily for the Symbols in the final_pmgus_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sps_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
