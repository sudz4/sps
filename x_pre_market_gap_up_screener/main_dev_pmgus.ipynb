{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmgus.ipynb\n",
    "\"Pre-Market Gap-Up Screener\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# show all pandas row width\n",
    "pd.set_option('display.max_rows', None)\n",
    "# show all pandas column width\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import yfinance as yf\n",
    "import datetime as datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #0 - DATA IMPORT |\n",
    "|-|\n",
    "| file import setup |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/tv_screen_gap-up_2024-11-20.csv\n",
      "1437\n",
      "0     NVDA\n",
      "1     MSFT\n",
      "2     META\n",
      "3    BRK.B\n",
      "4      LLY\n",
      "Name: Symbol, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# base file path and file path setup\n",
    "base_dir_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/' \n",
    "std_file_name_str = 'tv_screen_gap-up_'\n",
    "\n",
    "#####---------------------#####\n",
    "# screen_date = '2024-11-05' \n",
    "# screen_date = '2024-11-07'\n",
    "\n",
    "# screen_date = '2024-11-15'\n",
    "screen_date = '2024-11-20'\n",
    "#####---------------------#####\n",
    "\n",
    "file_type = '.csv'\n",
    "filename = base_dir_path + std_file_name_str + screen_date + file_type\n",
    "\n",
    "# read the csv file\n",
    "print(filename)\n",
    "trading_view_df = pd.read_csv(filename)\n",
    "print(len(trading_view_df))\n",
    "# print first 5 ticker Symbols only\n",
    "print(trading_view_df['Symbol'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #1 - SCREENER |\n",
    "|-|\n",
    "| xxx |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 stockes found in the screener.\n"
     ]
    }
   ],
   "source": [
    "def categorize_market_cap(df):\n",
    "    \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "    df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "    conditions = [\n",
    "        (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "        (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "        (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "        (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "        (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "        (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "    ]\n",
    "    categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "    df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "    return df\n",
    "\n",
    "# execute categorization\n",
    "category_setup_df = categorize_market_cap(trading_view_df).copy()\n",
    "\n",
    "# drop Undefined marketCapType\n",
    "category_setup_df = category_setup_df[category_setup_df['marketCapType'] != 'Undefined']\n",
    "\n",
    "# convert necessary columns to numeric\n",
    "def convert_columns_to_numeric(df, columns):\n",
    "    \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# list of columns to convert\n",
    "numeric_columns = [\n",
    "    'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "    'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "    'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "    'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "]\n",
    "\n",
    "# Apply conversion\n",
    "category_setup_df = convert_columns_to_numeric(category_setup_df, numeric_columns)\n",
    "\n",
    "# Criteria configuration for each market cap category\n",
    "criteria_config = {\n",
    "    \"Titans\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "        \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.03,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Large caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "        \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "        \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "        \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "        \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    # \"Midlers\" in TradingView\n",
    "    \"Midlers\": { \n",
    "        \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "        \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "        \"relative_volume_threshold\": 1.3,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Small caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "        \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Micro caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "        \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "        \"relative_volume_threshold\": 1.1,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Shrimp\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "        \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "        \"relative_volume_threshold\": 1.0,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    }\n",
    "}\n",
    "\n",
    "def filter_stocks(df, config):\n",
    "    \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "    conditions = (\n",
    "        (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "        (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "        (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "        (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "        (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "        (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "        (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "    )\n",
    "    return df[conditions]\n",
    "\n",
    "def screen_stocks_by_category(df, category):\n",
    "    \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "    config = criteria_config.get(category, {})\n",
    "    filtered_df = filter_stocks(df, config)\n",
    "    return filtered_df\n",
    "\n",
    "# execute filtering\n",
    "smash_df = pd.DataFrame()\n",
    "categories = category_setup_df['marketCapType'].unique()\n",
    "\n",
    "for category in categories:\n",
    "    category_df = category_setup_df[category_setup_df['marketCapType'] == category]\n",
    "    gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "    smash_df = pd.concat([smash_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# add 'Market capitalization' to the reordered columns list\n",
    "cols_list = [\n",
    "    'Symbol', \n",
    "    'Description', \n",
    "    'marketCapType', \n",
    "    'Pre-market Change %', \n",
    "    'Pre-market Gap %', \n",
    "    'marketCapType',\n",
    "    'Market capitalization',\n",
    "    'Price', \n",
    "    'Pre-market Open', \n",
    "    'Industry', \n",
    "    'Index', \n",
    "    'Sector', \n",
    "    'Exchange',\n",
    "    'Recent earnings date', \n",
    "    'Upcoming earnings date', \n",
    "    'Float shares outstanding', \n",
    "    'Average Volume 10 days',\n",
    "    'Average Volume 30 days', \n",
    "    'Average Volume 90 days',\n",
    "    'Relative Volume 1 day', \n",
    "    'Relative Volume 5 minutes', \n",
    "    'Relative Volume 30 minutes', \n",
    "    'Relative Volume at Time', \n",
    "    'Analyst Rating'\n",
    "]\n",
    "\n",
    "# filter columns to only include those present in the DataFrame\n",
    "existing_cols = [col for col in cols_list if col in smash_df.columns]\n",
    "smash_df = smash_df[existing_cols]\n",
    "\n",
    "# sort and reset index\n",
    "smash_df = smash_df.sort_values(\n",
    "    by=['Pre-market Change %', 'Price'],\n",
    "    ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(f\"{smash_df.shape[0]} stockes found in the screener.\")\n",
    "# ## ISSUE ##\n",
    "# #### HARD CODED FILE PATH ####\n",
    "# # also change this if you add another level, you probably will to screener_smoke \n",
    "# # output_filename = f'pre_market_gap_up_screener_targets_{today_date_str}.csv'\n",
    "# output_filename = f'/Users/sudz4/Desktop/BOOK-II/nowbear/stgy_pm-gap-up-screener/data_pmgus/output_pmgus/pre_market_gap_up_screener_targets_2024-09-26.csv'\n",
    "\n",
    "# smash_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(smash_df.head(4))\n",
    "display(smash_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "84\n",
      "['XCUR', 'WIX', 'GLBE', 'ZIM', 'MSTR', 'LMND', 'EE', 'RUM', 'CORZ', 'BPMC', 'LNTH', 'ACHR', 'KT', 'ERJ', 'HAFN', 'SKYW', 'MTSI', 'EXAS', 'CRDO', 'SOBO', 'UFPI', 'BKE', 'SOUN', 'KNF', 'OSCR', 'AMBA', 'MGNI', 'AEIS', 'RSI', 'GVA', 'NXE', 'KBH', 'TRUP', 'CRS', 'ROAD', 'ENIC', 'GEO', 'U', 'PRKS', 'MASI', 'SWTX', 'RDNT', 'NOV', 'PI', 'PTON', 'LFST', 'CXW', 'CXT', 'NPWR', 'MAIN', 'BRBR', 'INTA', 'SHAK', 'CWAN', 'CSWI', 'SMTC', 'IESC', 'CPA', 'CNXC', 'ADUS', 'OBDC', 'BROS', 'ALK', 'CZR', 'VRNA', 'FSK', 'WB', 'S', 'CRGY', 'CLF', 'PLNT', 'STR', 'AVPT', 'BXSL', 'RVLV', 'GOGL', 'CALX', 'ITRI', 'SG', 'ADMA', 'VCTR', 'CFLT', 'AXSM', 'RLX']\n"
     ]
    }
   ],
   "source": [
    "# return smash_list of Symbols\n",
    "smash_list = smash_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "print(len(smash_df))\n",
    "print(len(smash_list))\n",
    "print(smash_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return current stock price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"quick back test\"\n",
    "which tickers from smash_list did well on today\n",
    "1-baseline buy sell w/same time b/s\n",
    "2-dynamic sell same buy\n",
    "\n",
    "1-specific day to back test\n",
    "2-move code over for specific times\n",
    "3-baseline times\n",
    "4-other ideas time segments\n",
    "5-dynamic buy windows IF only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20\n"
     ]
    }
   ],
   "source": [
    "# start----quick back test function\n",
    "print(screen_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Use datetime.strptime() where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_backtest(df, test_date, num_stocks=4):\n",
    "    \"\"\"\n",
    "    Perform quick backtest for specified stocks on a specific historical date.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing screened stocks\n",
    "    test_date (str): Date to test in 'YYYY-MM-DD' format\n",
    "    num_stocks (int): Number of stocks to test (default=4)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with historical intraday data for tested stocks\n",
    "    \"\"\"\n",
    "    # Take first n stocks\n",
    "    symbols = df['Symbol'].tolist()[:num_stocks]\n",
    "    stock_data = {}\n",
    "    \n",
    "    # Calculate end date (next day)\n",
    "    start_date = datetime.strptime(test_date, '%Y-%m-%d')\n",
    "    end_date = start_date + timedelta(days=1)\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            ticker = yf.Ticker(symbol)\n",
    "            # Get 1-minute data for the specified day\n",
    "            hist_data = ticker.history(\n",
    "                start=start_date.strftime('%Y-%m-%d'),\n",
    "                end=end_date.strftime('%Y-%m-%d'),\n",
    "                interval='1m'\n",
    "            )\n",
    "            \n",
    "            if not hist_data.empty:\n",
    "                # Store all minute data for the day\n",
    "                stock_data[symbol] = {\n",
    "                    'Open': hist_data['Open'].tolist(),\n",
    "                    'High': hist_data['High'].tolist(),\n",
    "                    'Low': hist_data['Low'].tolist(),\n",
    "                    'Close': hist_data['Close'].tolist(),\n",
    "                    'Volume': hist_data['Volume'].tolist(),\n",
    "                    'Timestamps': hist_data.index.tolist(),\n",
    "                    'Day_High': hist_data['High'].max(),\n",
    "                    'Day_Low': hist_data['Low'].min(),\n",
    "                    'Open_Price': hist_data['Open'].iloc[0],\n",
    "                    'Close_Price': hist_data['Close'].iloc[-1],\n",
    "                    'Total_Volume': hist_data['Volume'].sum(),\n",
    "                    'Time_of_Day_High': hist_data['High'].idxmax(),\n",
    "                    'Time_of_Day_Low': hist_data['Low'].idxmin()\n",
    "                }\n",
    "                \n",
    "                # Calculate basic statistics\n",
    "                stock_data[symbol]['Intraday_Return'] = (\n",
    "                    (stock_data[symbol]['Close_Price'] - stock_data[symbol]['Open_Price']) \n",
    "                    / stock_data[symbol]['Open_Price'] * 100\n",
    "                )\n",
    "                \n",
    "                stock_data[symbol]['Max_Gain'] = (\n",
    "                    (stock_data[symbol]['Day_High'] - stock_data[symbol]['Open_Price'])\n",
    "                    / stock_data[symbol]['Open_Price'] * 100\n",
    "                )\n",
    "                \n",
    "                stock_data[symbol]['Max_Loss'] = (\n",
    "                    (stock_data[symbol]['Day_Low'] - stock_data[symbol]['Open_Price'])\n",
    "                    / stock_data[symbol]['Open_Price'] * 100\n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                print(f\"No data available for {symbol} on {test_date}\")\n",
    "                stock_data[symbol] = {\n",
    "                    'Open': None, 'High': None, 'Low': None, 'Close': None,\n",
    "                    'Volume': None, 'Timestamps': None, 'Day_High': None,\n",
    "                    'Day_Low': None, 'Open_Price': None, 'Close_Price': None,\n",
    "                    'Total_Volume': None, 'Intraday_Return': None,\n",
    "                    'Max_Gain': None, 'Max_Loss': None,\n",
    "                    'Time_of_Day_High': None, 'Time_of_Day_Low': None\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {symbol}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    results_df = pd.DataFrame.from_dict(stock_data, orient='index')\n",
    "    \n",
    "    # Add symbol as a column instead of index\n",
    "    results_df.reset_index(inplace=True)\n",
    "    results_df.rename(columns={'index': 'Symbol'}, inplace=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-20\n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "print(screen_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$XCUR: possibly delisted; no price data found  (1m 2024-11-20 -> 2024-11-21)\n",
      "$WIX: possibly delisted; no price data found  (1m 2024-11-20 -> 2024-11-21)\n",
      "$GLBE: possibly delisted; no price data found  (1m 2024-11-20 -> 2024-11-21)\n",
      "$ZIM: possibly delisted; no price data found  (1m 2024-11-20 -> 2024-11-21)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available for XCUR on 2024-11-20\n",
      "No data available for WIX on 2024-11-20\n",
      "No data available for GLBE on 2024-11-20\n",
      "No data available for ZIM on 2024-11-20\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Timestamps</th>\n",
       "      <th>Day_High</th>\n",
       "      <th>Day_Low</th>\n",
       "      <th>Open_Price</th>\n",
       "      <th>Close_Price</th>\n",
       "      <th>Total_Volume</th>\n",
       "      <th>Intraday_Return</th>\n",
       "      <th>Max_Gain</th>\n",
       "      <th>Max_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XCUR</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WIX</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLBE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZIM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol  Open  High   Low Close Volume Timestamps Day_High Day_Low  \\\n",
       "0   XCUR  None  None  None  None   None       None     None    None   \n",
       "1    WIX  None  None  None  None   None       None     None    None   \n",
       "2   GLBE  None  None  None  None   None       None     None    None   \n",
       "3    ZIM  None  None  None  None   None       None     None    None   \n",
       "\n",
       "  Open_Price Close_Price Total_Volume Intraday_Return Max_Gain Max_Loss  \n",
       "0       None        None         None            None     None     None  \n",
       "1       None        None         None            None     None     None  \n",
       "2       None        None         None            None     None     None  \n",
       "3       None        None         None            None     None     None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute backtest\n",
    "qbt_df = quick_backtest(smash_df, screen_date)\n",
    "\n",
    "# Print basic info\n",
    "print(f\"Number of stocks analyzed: {len(qbt_df)}\")\n",
    "\n",
    "# Create a summary view with key metrics\n",
    "summary_cols = [\n",
    "    'Symbol', 'Open_Price', 'Close_Price', 'Day_High', 'Day_Low',\n",
    "    'Time_of_Day_High', 'Time_of_Day_Low', \n",
    "    'Intraday_Return', 'Max_Gain', 'Max_Loss', 'Total_Volume'\n",
    "]\n",
    "\n",
    "# Display summary with better formatting\n",
    "summary_df = qbt_df[summary_cols].copy()\n",
    "summary_df['Intraday_Return'] = summary_df['Intraday_Return'].round(2)\n",
    "summary_df['Max_Gain'] = summary_df['Max_Gain'].round(2)\n",
    "summary_df['Max_Loss'] = summary_df['Max_Loss'].round(2)\n",
    "summary_df['Total_Volume'] = summary_df['Total_Volume'].astype(float).round(0)\n",
    "\n",
    "print(\"\\nBacktest Summary:\")\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "####---quick start back tests\n",
    "def quick_backtest(df, day):\n",
    "    symbols = df['Symbol'].tolist()\n",
    "    stock_data = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    "        ticker = yf.Ticker(symbol)\n",
    "        qbt_data = ticker.history(start=day, end=(datetime.strptime(day, '%Y-%m-%d') + timedelta(days=1)).strftime('%Y-%m-%d'), interval='1m')\n",
    "\n",
    "        if not qbt_data.empty:\n",
    "            stock_data[symbol] = {\n",
    "                'High': qbt_data['High'].values[0],\n",
    "                'Low': qbt_data['Low'].values[0],\n",
    "                'Open': qbt_data['Open'].values[0],\n",
    "                'Close': qbt_data['Close'].values[0],\n",
    "                'Volume': qbt_data['Volume'].values[0],\n",
    "                'Date': qbt_data.index[0]\n",
    "            }\n",
    "        else:\n",
    "            qbt_data[symbol] = {\n",
    "                'High': None,\n",
    "                'Low': None,\n",
    "                'Open': None,\n",
    "                'Close': None,\n",
    "                'Volume': None,\n",
    "                'Date': None\n",
    "            }\n",
    "\n",
    "    qbt_df = pd.DataFrame(qbt_data).T.reset_index().rename(columns={'index': 'Symbol'})\n",
    "    \n",
    "    ####\n",
    "\n",
    "    return qbt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame from the stock data dictionary\n",
    "    stock_data_df = pd.DataFrame(stock_data).T.reset_index().rename(columns={'index': 'Symbol'})\n",
    "    \n",
    "    # merge the new stock data with the existing DataFrame\n",
    "    updated_df = pd.merge(df, stock_data_df, on='Symbol', how='left')\n",
    "    \n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add high low close\n",
    "#### ---- Quick Stary Backtesting ---- ####\n",
    "def basic_daily_technicals(df):\n",
    "    symbols = df['Symbol'].tolist()\n",
    "    stock_data = {}\n",
    "\n",
    "    for symbol in symbols:\n",
    "        stock_info = yf.Ticker(symbol)\n",
    "        today_data = stock_info.history(period='1d')\n",
    "        \n",
    "        if not today_data.empty:\n",
    "            stock_data[symbol] = {\n",
    "                'High': today_data['High'].values[0],\n",
    "                'Low': today_data['Low'].values[0],\n",
    "                'Open': today_data['Open'].values[0],\n",
    "                'Close': today_data['Close'].values[0],\n",
    "                'Volume': today_data['Volume'].values[0],\n",
    "                'Date': today_data.index[0]\n",
    "            }\n",
    "        else:\n",
    "            stock_data[symbol] = {\n",
    "                'High': None,\n",
    "                'Low': None,\n",
    "                'Open': None,\n",
    "                'Close': None,\n",
    "                'Volume': None,\n",
    "                'Date': None\n",
    "            }\n",
    "\n",
    "    # create a DataFrame from the stock data dictionary\n",
    "    stock_data_df = pd.DataFrame(stock_data).T.reset_index().rename(columns={'index': 'Symbol'})\n",
    "    \n",
    "    # merge the new stock data with the existing DataFrame\n",
    "    updated_df = pd.merge(df, stock_data_df, on='Symbol', how='left')\n",
    "    \n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #2 - SCREENER |\n",
    "|-|\n",
    "| TECHNICAL INDICATORS - via yahoo finance |\n",
    "\n",
    "*note yahoo finance data source transition\n",
    "*feels like this is more of a swing screen????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# from ta.trend import MACD\n",
    "# from ta.momentum import RSIIndicator\n",
    "# from ta.trend import SMAIndicator\n",
    "# from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "# from ta.trend import SMAIndicator, MACD, PSARIndicator\n",
    "# from ta.volatility import BollingerBands, AverageTrueRange\n",
    "# from ta.volume import OnBalanceVolumeIndicator\n",
    "# # import vectorbt as vbt\n",
    "# # vbt.settings.set_theme('dark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "# from ta.momentum import RSIIndicator\n",
    "# from ta.trend import SMAIndicator, MACD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add start date as a var for retroactive testing / backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_technical_indicators(df):\n",
    "#     tech_data = []\n",
    "\n",
    "#     for symbol in df['Symbol'].unique():\n",
    "#         data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "#         if not data.empty:\n",
    "#             close_prices = data['Close'].squeeze()  # Ensure it's a 1-dimensional series\n",
    "#             rsi = RSIIndicator(close_prices, window=14).rsi().iloc[-1] # last value!\n",
    "#             ma20 = SMAIndicator(close_prices, window=20).sma_indicator().iloc[-1] # last value!\n",
    "#             ma50 = SMAIndicator(close_prices, window=50).sma_indicator().iloc[-1] # last value!\n",
    "#             macd = MACD(close_prices).macd_diff().iloc[-1] # last value!\n",
    "\n",
    "#             tech_data.append({\n",
    "#                 'Symbol': symbol,\n",
    "#                 'RSI': rsi,\n",
    "#                 'MA20': ma20,\n",
    "#                 'MA50': ma50,\n",
    "#                 'MACD': macd,\n",
    "#                 'Yahoo Price': close_prices.iloc[-1], # last value! (price from Yahoo!)\n",
    "#             })\n",
    "\n",
    "#     tech_df = pd.DataFrame(tech_data)\n",
    "#     return tech_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the last value because,\n",
    "technically for back testing you want to pay attention here.\n",
    "real time go time i think we want it most recent. meaning yesterday\n",
    "if we are making decisions and in pre-market trading hours based on the Close from yesterday\n",
    "yesterday = last Close $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode_df = compute_technical_indicators(smash_df)\n",
    "\n",
    "# print(explode_df.shape)\n",
    "# print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(explode_df.shape)\n",
    "# print(explode_df.head())\n",
    "\n",
    "# print(smash_df.shape)\n",
    "# print(smash_df.iloc[:5,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def screen_stocks_by_technical_indicators(df):\n",
    "#     # filter based on RSI, MA, and MACD\n",
    "#     df = df[(df['RSI'] >= 0) & (df['RSI'] < 70)]  # RSI filter condition\n",
    "#     df = df[df['Yahoo Price'] > df['MA20']]\n",
    "#     df = df[df['Yahoo Price'] > df['MA50']]\n",
    "#     df = df[df['MACD'] > 0]\n",
    "#     \"\"\" \n",
    "#     # should i add more to this?\n",
    "#     # level 3 will start to get more advanced filering\n",
    "#     # dont want to overfilter to soon also and miss something\n",
    "#     # patience\n",
    "#     \"\"\"\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explode_df = screen_stocks_by_technical_indicators(explode_df)\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # return explode_list of Symbols\n",
    "# explode_list = explode_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "# print(len(smash_df))\n",
    "# print()\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(len(explode_list))\n",
    "# print(explode_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(explode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(screen_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sory descending by RSI\n",
    "# explode_df = explode_df.sort_values(by='RSI', ascending=True)\n",
    "\n",
    "# print(explode_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #3 - SCREENER |\n",
    "|-|\n",
    "| xxx |\n",
    "\n",
    "i think this is the place for those small tactical screeners\n",
    "maybe even think about deploying dynamically for instance one above this ta technical screener filter\n",
    "different days, different vols, and volatilty\n",
    "\n",
    "see index specific\n",
    "see vix\n",
    "companies in same industry, same sector, same location? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #4 - SCREENER |\n",
    "|-|\n",
    "| xxx |\n",
    "\n",
    "could think about doing additional available (but separate now) on the subset, additional technical indicators from ta library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "# from ta.trend import SMAIndicator, MACD, CCIIndicator\n",
    "# from ta.volatility import BollingerBands\n",
    "# from ta.volume import OnBalanceVolumeIndicator\n",
    "# from ta.volatility import AverageTrueRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_additional_indicators(df):\n",
    "#     additional_data = []\n",
    "\n",
    "#     for symbol in df['Symbol'].unique():\n",
    "#         data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "#         if not data.empty:\n",
    "#             close_prices = data['Close'].squeeze()  # Ensure it's a 1-dimensional series\n",
    "#             high_prices = data['High'].squeeze()\n",
    "#             low_prices = data['Low'].squeeze()\n",
    "#             volume = data['Volume'].squeeze()\n",
    "\n",
    "#             # Compute additional indicators\n",
    "#             bb = BollingerBands(close_prices)\n",
    "#             atr = AverageTrueRange(high=high_prices, low=low_prices, close=close_prices)\n",
    "#             stoch = StochasticOscillator(close=close_prices, high=high_prices, low=low_prices)\n",
    "#             obv = OnBalanceVolumeIndicator(close=close_prices, volume=volume)\n",
    "#             cci = CCIIndicator(high=high_prices, low=low_prices, close=close_prices)\n",
    "\n",
    "#             additional_data.append({\n",
    "#                 'Symbol': symbol,\n",
    "#                 'Bollinger High': bb.bollinger_hband().iloc[-1],\n",
    "#                 'Bollinger Low': bb.bollinger_lband().iloc[-1],\n",
    "#                 'ATR': atr.average_true_range().iloc[-1],\n",
    "#                 'Stochastic Oscillator': stoch.stoch().iloc[-1],\n",
    "#                 'OBV': obv.on_balance_volume().iloc[-1],\n",
    "#                 'CCI': cci.cci().iloc[-1],\n",
    "#             })\n",
    "\n",
    "#     additional_df = pd.DataFrame(additional_data)\n",
    "#     return additional_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_explode_df = compute_additional_indicators(explode_df)\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(len(double_explode_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_explode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_additional_indicators(df):\n",
    "#     # Example filter criteria\n",
    "#     filtered_df = df[\n",
    "#         (df['Stochastic Oscillator'] < 20) &  # Stochastic Oscillator indicates oversold\n",
    "#         (df['CCI'] < -100) &  # CCI indicates oversold\n",
    "#         (df['ATR'] > 1)  # ATR indicates high volatility\n",
    "#     ]\n",
    "#     return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_double_explode_df = filter_additional_indicators(double_explode_df)\n",
    "\n",
    "\n",
    "# print(len(explode_df))\n",
    "# print(len(filtered_double_explode_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #5,#6 - SCREENER |\n",
    "|-|\n",
    "| (mini) tight screeners - (toggle on and off w/comments?) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return index data for relevant?\n",
    "good time to see if that chart works opensource similar to tradingview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could also plot historical data for 53 stocks who cares. check it out on same chart?\n",
    "watch a youtube\n",
    "restart as new feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what about news\n",
    "what about europe /asia price action\n",
    "market and industry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Notes |\n",
    "|-|\n",
    "| END of WORKING CODE |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data file from TradingView to pandas df\n",
    "# \"\"\" \n",
    "# Market : US\n",
    "# Exchange : NASDAQ, NYSE\n",
    "# Pre-market Chg > $0.00 USD\n",
    "\n",
    "# Stocks = ~1100\n",
    "# \"\"\"\n",
    "# base_file_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/'\n",
    "# file_name =  'tv_screen_gap-up_2024-10-29.csv'\n",
    "# pmgus_df = pd.read_csv(base_file_path + file_name)\n",
    "\n",
    "\n",
    "# print(len(pmgus_df))\n",
    "# pmgus_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_market_cap(df):\n",
    "#     \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "#     conditions = [\n",
    "#         (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "#         (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "#         (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "#         (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "#         (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "#         (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "#     ]\n",
    "#     categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "#     df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "#     # drop Undefined\n",
    "#     df = df[df['marketCapType'] != 'Undefined']\n",
    "#     # convert to numeric the Market capitalization column\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'])\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - categorize market cap\n",
    "# pmgus_df = categorize_market_cap(pmgus_df).copy()\n",
    "# print(len(pmgus_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert necessary columns to numeric\n",
    "# def convert_columns_to_numeric(df, columns):\n",
    "#     \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "#     for col in columns:\n",
    "#         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "#     return df\n",
    "\n",
    "# # list of columns to convert\n",
    "# numeric_columns = [\n",
    "#     'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "#     'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "#     'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "#     'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - convert columns to numeric\n",
    "# pmgus_df = convert_columns_to_numeric(pmgus_df, numeric_columns).copy()\n",
    "# print(len(pmgus_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria configuration for each market cap category\n",
    "# criteria_config = {\n",
    "#     \"Titans\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "#         \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.03,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "#         \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "#         \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     # \"Midlers\" in TradingView\n",
    "#     \"Midlers\": { \n",
    "#         \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "#         \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "#         \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "#         \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "#         \"relative_volume_threshold\": 1.1,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "#         \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "#         \"relative_volume_threshold\": 1.0,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_stocks(df, config):\n",
    "#     \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "#     conditions = (\n",
    "#         (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "#         (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "#         (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "#         (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "#         (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "#         (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "#         (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# def screen_stocks_by_category(df, category):\n",
    "#     \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "#     config = criteria_config.get(category, {})\n",
    "#     filtered_df = filter_stocks(df, config)\n",
    "#     return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for category in pmgus_df['marketCapType'].unique():\n",
    "#     category_df = pmgus_df[pmgus_df['marketCapType'] == category]\n",
    "#     gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "#     pmgus_two_df = pd.concat([category_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# print(len(pmgus_two_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enhanced volume screening -L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_cap_volume_thresholds = {\n",
    "#     \"Titans\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.001,  # 0.1% of ADV minimum in pre-market\n",
    "#         \"min_rel_vol_5min\": 1.5,        # 50% above normal 5-min volume\n",
    "#         \"min_rel_vol_15min\": 1.3        # 30% above normal 15-min volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.002,  # 0.2% of ADV\n",
    "#         \"min_rel_vol_5min\": 1.8,\n",
    "#         \"min_rel_vol_15min\": 1.5\n",
    "#     },\n",
    "#     \"Midlers\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.003,  # 0.3% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.0,\n",
    "#         \"min_rel_vol_15min\": 1.7\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.004,  # 0.4% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.5,\n",
    "#         \"min_rel_vol_15min\": 2.0\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.005,  # 0.5% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.0,\n",
    "#         \"min_rel_vol_15min\": 2.5\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.008,  # 0.8% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.5,\n",
    "#         \"min_rel_vol_15min\": 3.0\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# def analyze_premarket_volume_by_cap(df, conditions):\n",
    "#     \"\"\"\n",
    "#     Enhanced volume analysis based on market cap category with progressive thresholds\n",
    "#     \"\"\"\n",
    "#     df['PM_Volume_Ratio'] = df['Pre-market Volume'] / df['Average Volume 10 days']\n",
    "#     df['Volume_Acceleration'] = df['Relative Volume 5 minutes'] / df['Relative Volume 15 minutes']\n",
    "    \n",
    "#     # Apply filters based on market cap category\n",
    "#     conditions = []\n",
    "#     for cap_type, thresholds in market_cap_volume_thresholds.items():\n",
    "#         cap_condition = (\n",
    "#             (df['marketCapType'] == cap_type) &\n",
    "#             (df['PM_Volume_Ratio'] >= thresholds['min_pm_volume_vs_adv']) &\n",
    "#             (df['Relative Volume 5 minutes'] >= thresholds['min_rel_vol_5min']) &\n",
    "#             (df['Relative Volume 15 minutes'] >= thresholds['min_rel_vol_15min'])\n",
    "#         )\n",
    "#         conditions.append(cap_condition)\n",
    "    \n",
    "#     return pd.concat([df[cond] for cond in conditions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show all pandas row width\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# # show all pandas column width\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmgus_two_df = analyze_premarket_volume_by_cap(pmgus_two_df, market_cap_volume_thresholds)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))\n",
    "# display(pmgus_two_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# new_pmgus_df.to_csv(base_file_path + 'new_pmgus_2024-10-29_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))\n",
    "# print(len(pmgus_two_df.columns))\n",
    "# print(pmgus_two_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final L1 FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define no negatives\n",
    "# def no_negatives(df):\n",
    "#     \"\"\"Remove negative values in the data frame.\"\"\"\n",
    "#     return df[(df['Pre-market Change %'] >= 0) & (df['Pre-market Gap %'] >= 0)]\n",
    "\n",
    "# # apply no negatives\n",
    "# pmgus_two_df = no_negatives(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def technical_price_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter stocks based on their position relative to key technical levels\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price near recent highs suggesting momentum\n",
    "#         (df['Price'] >= df['High 1 month'] * 0.85) |  \n",
    "        \n",
    "#         # Price above all major SMAs showing strength\n",
    "#         (df['Price'] > df['Simple Moving Average (5) 1 minute']) &\n",
    "#         (df['Price'] > df['Simple Moving Average (13) 5 minutes']) &\n",
    "        \n",
    "#         # Price near upper Bollinger Band suggesting strength\n",
    "#         (df['Price'] >= df['Bollinger Bands (20) 5 minutes, Basis'])\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply technical price filter\n",
    "# pmgus_two_df = technical_price_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "might need to back off a little on the volatility filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fundamental_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter using analyst ratings and price targets\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price well below analyst targets suggesting upside\n",
    "#         (df['Target price 1 year'] > df['Price'] * 1.2) &\n",
    "        \n",
    "#         # Strong analyst ratings\n",
    "#         (df['Analyst Rating'].isin(['Strong buy', 'Buy']))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply fundamental filter\n",
    "# pmgus_two_df = fundamental_filter(pmgus_two_df)\n",
    "\n",
    "# # sort by change percentage descending\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def volatility_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter for stocks showing increasing volatility\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Increasing volatility pattern\n",
    "#         (df['Volatility 1 day'] > df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 week'] > df['Volatility 1 month']) &\n",
    "        \n",
    "#         # Beta filter for more responsive stocks\n",
    "#         (df['Beta 1 year'] > 1.0)\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply volatility filter\n",
    "# pmgus_two_df = volatility_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort by largest change percentage\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "# # look at data after initial filters\n",
    "# print(len(pmgus_two_df))\n",
    "# # display(pmgus_two_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # return symbol and price and analyst rating\n",
    "# pmgus_two_df[['Symbol', 'Price', 'Analyst Rating', 'marketCapType']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL GRANULAR FILTERS (when needed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want another volume one slightly more granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Price above short-term moving averages indicating immediate strength\n",
    "# price_conditions = (\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (5) 1 minute']) &\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (8) 1 minute'])\n",
    "# )\n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[price_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Volume additioal acceleration\n",
    "# vol_addtl_accel_conditions = (\n",
    "#     (pmgus_two_df['Relative Volume 1 minute'] > pmgus_two_df['Relative Volume 5 minutes']) &\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > 1.5)  &  # Strong recent volume\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > pmgus_two_df['Relative Volume 15 minutes']) &  # Accelerating volume\n",
    "#     (pmgus_two_df['Relative Volume 15 minutes'] > pmgus_two_df['Relative Volume 30 minutes'])) # building momentum \n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[vol_addtl_accel_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of additional filters when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open source tradingview type chart view. \n",
    "# then use historical data and plat the daily for the Symbols in the final_pmgus_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sps_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
