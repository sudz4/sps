{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pmgus.ipynb\n",
    "\"Pre-Market Gap-Up Screener\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# show all pandas row width\n",
    "pd.set_option('display.max_rows', None)\n",
    "# show all pandas column width\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #0 - DATA IMPORT |\n",
    "|-|\n",
    "| file import setup |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/tv_screen_gap-up_2024-11-07.csv\n",
      "1696\n",
      "0    NVDA\n",
      "1    AAPL\n",
      "2    MSFT\n",
      "3    AMZN\n",
      "4    GOOG\n",
      "Name: Symbol, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# base file path and file path setup\n",
    "base_dir_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/' \n",
    "std_file_name_str = 'tv_screen_gap-up_'\n",
    "\n",
    "#####---------------------#####\n",
    "screen_date = '2024-11-07'\n",
    "#####---------------------#####\n",
    "\n",
    "file_type = '.csv'\n",
    "filename = base_dir_path + std_file_name_str + screen_date + file_type\n",
    "\n",
    "# read the csv file\n",
    "print(filename)\n",
    "trading_view_df = pd.read_csv(filename)\n",
    "print(len(trading_view_df))\n",
    "# print first 5 ticker Symbols only\n",
    "print(trading_view_df['Symbol'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #1 - SCREENER |\n",
    "|-|\n",
    "| xxx |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181 stockes found in the screener.\n"
     ]
    }
   ],
   "source": [
    "def categorize_market_cap(df):\n",
    "    \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "    df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "    conditions = [\n",
    "        (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "        (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "        (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "        (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "        (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "        (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "    ]\n",
    "    categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "    df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "    return df\n",
    "\n",
    "# execute categorization\n",
    "category_setup_df = categorize_market_cap(trading_view_df).copy()\n",
    "\n",
    "# drop Undefined marketCapType\n",
    "category_setup_df = category_setup_df[category_setup_df['marketCapType'] != 'Undefined']\n",
    "\n",
    "# convert necessary columns to numeric\n",
    "def convert_columns_to_numeric(df, columns):\n",
    "    \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# list of columns to convert\n",
    "numeric_columns = [\n",
    "    'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "    'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "    'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "    'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "]\n",
    "\n",
    "# Apply conversion\n",
    "category_setup_df = convert_columns_to_numeric(category_setup_df, numeric_columns)\n",
    "\n",
    "# Criteria configuration for each market cap category\n",
    "criteria_config = {\n",
    "    \"Titans\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "        \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.03,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Large caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "        \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "        \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "        \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "        \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    # \"Midlers\" in TradingView\n",
    "    \"Midlers\": { \n",
    "        \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "        \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "        \"relative_volume_threshold\": 1.3,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Small caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "        \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "        \"relative_volume_threshold\": 1.2,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Micro caps\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "        \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "        \"relative_volume_threshold\": 1.1,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    },\n",
    "    \"Shrimp\": {\n",
    "        \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "        \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "        \"relative_volume_threshold\": 1.0,\n",
    "        \"relative_volume_at_time_threshold\": 0.05,\n",
    "        \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "        \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "        \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "    }\n",
    "}\n",
    "\n",
    "def filter_stocks(df, config):\n",
    "    \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "    conditions = (\n",
    "        (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "        (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "        (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "        (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "        (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "        (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "        (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "        (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "    )\n",
    "    return df[conditions]\n",
    "\n",
    "def screen_stocks_by_category(df, category):\n",
    "    \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "    config = criteria_config.get(category, {})\n",
    "    filtered_df = filter_stocks(df, config)\n",
    "    return filtered_df\n",
    "\n",
    "# execute filtering\n",
    "smash_df = pd.DataFrame()\n",
    "categories = category_setup_df['marketCapType'].unique()\n",
    "\n",
    "for category in categories:\n",
    "    category_df = category_setup_df[category_setup_df['marketCapType'] == category]\n",
    "    gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "    smash_df = pd.concat([smash_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# add 'Market capitalization' to the reordered columns list\n",
    "cols_list = [\n",
    "    'Symbol', \n",
    "    'Description', \n",
    "    'marketCapType', \n",
    "    'Pre-market Change %', \n",
    "    'Pre-market Gap %', \n",
    "    'marketCapType',\n",
    "    'Market capitalization',\n",
    "    'Price', \n",
    "    'Pre-market Open', \n",
    "    'Industry', \n",
    "    'Index', \n",
    "    'Sector', \n",
    "    'Exchange',\n",
    "    'Recent earnings date', \n",
    "    'Upcoming earnings date', \n",
    "    'Float shares outstanding', \n",
    "    'Average Volume 10 days',\n",
    "    'Average Volume 30 days', \n",
    "    'Average Volume 90 days',\n",
    "    'Relative Volume 1 day', \n",
    "    'Relative Volume 5 minutes', \n",
    "    'Relative Volume 30 minutes', \n",
    "    'Relative Volume at Time', \n",
    "    'Analyst Rating'\n",
    "]\n",
    "\n",
    "# filter columns to only include those present in the DataFrame\n",
    "existing_cols = [col for col in cols_list if col in smash_df.columns]\n",
    "smash_df = smash_df[existing_cols]\n",
    "\n",
    "# sort and reset index\n",
    "smash_df = smash_df.sort_values(\n",
    "    by=['Pre-market Change %', 'Price'],\n",
    "    ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "print(f\"{smash_df.shape[0]} stockes found in the screener.\")\n",
    "# ## ISSUE ##\n",
    "# #### HARD CODED FILE PATH ####\n",
    "# # also change this if you add another level, you probably will to screener_smoke \n",
    "# # output_filename = f'pre_market_gap_up_screener_targets_{today_date_str}.csv'\n",
    "# output_filename = f'/Users/sudz4/Desktop/BOOK-II/nowbear/stgy_pm-gap-up-screener/data_pmgus/output_pmgus/pre_market_gap_up_screener_targets_2024-09-26.csv'\n",
    "\n",
    "# smash_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(smash_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "181\n",
      "['BROS', 'LYFT', 'GH', 'FRSH', 'CWAN', 'PLNT', 'MKSI', 'MTSI', 'LFST', 'ELF', 'USM', 'FUTU', 'BILI', 'CDE', 'KD', 'NVMI', 'ATGE', 'MNSO', 'SBSW', 'HIW', 'TDS', 'EDU', 'ALGM', 'HAE', 'BZ', 'ZIM', 'GOGL', 'YETI', 'APPN', 'SYM', 'WB', 'MLCO', 'PRMW', 'IQ', 'HBM', 'CENX', 'STEP', 'GXO', 'AVDX', 'HMY', 'SKYW', 'CAMT', 'NXST', 'ATAT', 'HAFN', 'YMM', 'QGEN', 'NSP', 'SID', 'QFIN', 'GGAL', 'TAL', 'PVH', 'MOG.A', 'SNDR', 'BIPC', 'SPSC', 'PAAS', 'IAG', 'PTEN', 'LSTR', 'WSFS', 'ABG', 'RXST', 'BBAR', 'BHVN', 'SKY', 'GKOS', 'PATH', 'SBLK', 'TDW', 'FRO', 'VIPS', 'X', 'XP', 'GPOR', 'CIG', 'VAC', 'SG', 'SGHC', 'UGI', 'SSB', 'GLOB', 'VVV', 'ZETA', 'AMBA', 'UPST', 'CLS', 'CLF', 'FFIN', 'EGO', 'WLY', 'AGX', 'INSW', 'ABCB', 'DOCN', 'RNA', 'CRDO', 'CPRI', 'SPNS', 'KMT', 'MP', 'OPCH', 'ACVA', 'MAIN', 'IOVA', 'GT', 'ASAN', 'HEES', 'HTGC', 'IEP', 'BBWI', 'TMDX', 'S', 'TTMI', 'DINO', 'UMBF', 'WK', 'GRND', 'NARI', 'BOH', 'VAL', 'GBDC', 'GAP', 'CWT', 'GTLS', 'ATKR', 'OMF', 'FLNC', 'ZI', 'PAGS', 'LEVI', 'BSM', 'PARA', 'KEX', 'SHAK', 'SWTX', 'BOX', 'PSEC', 'EBC', 'SEMR', 'DDS', 'MOD', 'FSK', 'AGNC', 'MTDR', 'JHG', 'TIMB', 'LBRT', 'KNX', 'SUN', 'MSM', 'KBH', 'CFR', 'GRFS', 'KRC', 'GOF', 'STNG', 'HCP', 'ROIC', 'BHF', 'OLN', 'UBSI', 'FULT', 'NOV', 'RH', 'CC', 'BXSL', 'POWL', 'TALO', 'FHB', 'CAR', 'WFRD', 'G', 'RDNT', 'APAM', 'BC', 'FOUR', 'YELP', 'CNX', 'SNV']\n"
     ]
    }
   ],
   "source": [
    "# return smash_list of Symbols\n",
    "smash_list = smash_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "print(len(smash_df))\n",
    "print(len(smash_list))\n",
    "print(smash_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #2 - SCREENER |\n",
    "|-|\n",
    "| TECHNICAL INDICATORS - via yahoo finance |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "\n",
    "# from ta.trend import MACD\n",
    "# from ta.momentum import RSIIndicator\n",
    "# from ta.trend import SMAIndicator\n",
    "# from ta.momentum import RSIIndicator, StochasticOscillator\n",
    "# from ta.trend import SMAIndicator, MACD, PSARIndicator\n",
    "# from ta.volatility import BollingerBands, AverageTrueRange\n",
    "# from ta.volume import OnBalanceVolumeIndicator\n",
    "# # import vectorbt as vbt\n",
    "# # vbt.settings.set_theme('dark')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import SMAIndicator, MACD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add start date as a var for retroactive testing / backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_technical_indicators(df):\n",
    "    tech_data = []\n",
    "\n",
    "    for symbol in df['Symbol'].unique():\n",
    "        data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "\n",
    "        if not data.empty:\n",
    "            close_prices = data['Close'].squeeze()  # Ensure it's a 1-dimensional series\n",
    "            rsi = RSIIndicator(close_prices, window=14).rsi().iloc[-1]\n",
    "            ma20 = SMAIndicator(close_prices, window=20).sma_indicator().iloc[-1]\n",
    "            ma50 = SMAIndicator(close_prices, window=50).sma_indicator().iloc[-1]\n",
    "            macd = MACD(close_prices).macd_diff().iloc[-1]\n",
    "\n",
    "            tech_data.append({\n",
    "                'Symbol': symbol,\n",
    "                'RSI': rsi,\n",
    "                'MA20': ma20,\n",
    "                'MA50': ma50,\n",
    "                'MACD': macd,\n",
    "                'Yahoo Price': close_prices.iloc[-1],  \n",
    "            })\n",
    "\n",
    "    tech_df = pd.DataFrame(tech_data)\n",
    "    return tech_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['MOG.A']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (period=6mo) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "  Symbol        RSI     MA20     MA50      MACD  Yahoo Price\n",
      "0   BROS  81.058225  34.8935  33.5134  0.587252    44.770000\n",
      "1   LYFT  80.493460  13.8600  12.8322  0.231033    17.690001\n",
      "2     GH  74.349977  22.1620  23.0764  0.808139    28.590000\n",
      "3   FRSH  90.257474  11.9495  11.5496  0.409639    16.820000\n",
      "4   CWAN  85.489232  26.9395  25.6394  0.397043    32.790001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "explode_df = compute_technical_indicators(smash_df)\n",
    "\n",
    "print(explode_df.shape)\n",
    "print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 6)\n",
      "   Symbol        RSI        MA20        MA50      MACD  Yahoo Price\n",
      "6    MKSI  65.461219  103.205999  106.649999  1.236327   115.639999\n",
      "8    LFST  68.613424    7.020000    6.900800  0.033908     7.680000\n",
      "9     ELF  56.691470  108.638500  113.058200  1.009225   116.070000\n",
      "10    USM  63.255734   60.398000   57.615400  0.196711    64.620003\n",
      "11   FUTU  64.326873   96.428750   86.113700  0.097108   108.660004\n",
      "(181, 24)\n",
      "  Symbol                          Description marketCapType\n",
      "0   BROS                      Dutch Bros Inc.      Mid caps\n",
      "1   LYFT                           Lyft, Inc.      Mid caps\n",
      "2     GH                Guardant Health, Inc.      Mid caps\n",
      "3   FRSH                      Freshworks Inc.      Mid caps\n",
      "4   CWAN  Clearwater Analytics Holdings, Inc.      Mid caps\n"
     ]
    }
   ],
   "source": [
    "print(explode_df.shape)\n",
    "print(explode_df.head())\n",
    "\n",
    "print(smash_df.shape)\n",
    "print(smash_df.iloc[:5,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screen_stocks_by_technical_indicators(df):\n",
    "    # filter based on RSI, MA, and MACD\n",
    "    df = df[(df['RSI'] >= 0) & (df['RSI'] < 70)]  # RSI filter condition\n",
    "    df = df[df['Yahoo Price'] > df['MA20']]\n",
    "    df = df[df['Yahoo Price'] > df['MA50']]\n",
    "    df = df[df['MACD'] > 0]\n",
    "    \"\"\" \n",
    "    # should i add more to this?\n",
    "    # level 3 will start to get more advanced filering\n",
    "    # dont want to overfilter to soon also and miss something\n",
    "    # patience\n",
    "    \"\"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "   Symbol        RSI        MA20        MA50      MACD  Yahoo Price\n",
      "6    MKSI  65.461219  103.205999  106.649999  1.236327   115.639999\n",
      "8    LFST  68.613424    7.020000    6.900800  0.033908     7.680000\n",
      "9     ELF  56.691470  108.638500  113.058200  1.009225   116.070000\n",
      "10    USM  63.255734   60.398000   57.615400  0.196711    64.620003\n",
      "11   FUTU  64.326873   96.428750   86.113700  0.097108   108.660004\n"
     ]
    }
   ],
   "source": [
    "explode_df = screen_stocks_by_technical_indicators(explode_df)\n",
    "\n",
    "print(len(explode_df))\n",
    "print(explode_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "\n",
      "73\n",
      "73\n",
      "['MKSI', 'LFST', 'ELF', 'USM', 'FUTU', 'BILI', 'NVMI', 'MNSO', 'ALGM', 'ZIM', 'YETI', 'SYM', 'STEP', 'CAMT', 'QGEN', 'SID', 'TAL', 'PVH', 'PTEN', 'LSTR', 'WSFS', 'SKY', 'GKOS', 'PATH', 'X', 'GPOR', 'SG', 'SSB', 'VVV', 'ZETA', 'AMBA', 'FFIN', 'WLY', 'ABCB', 'RNA', 'SPNS', 'KMT', 'ACVA', 'IOVA', 'GT', 'HEES', 'BBWI', 'S', 'UMBF', 'NARI', 'GAP', 'OMF', 'BSM', 'KEX', 'EBC', 'SEMR', 'DDS', 'FSK', 'MTDR', 'KNX', 'SUN', 'MSM', 'CFR', 'GRFS', 'GOF', 'HCP', 'BHF', 'UBSI', 'FULT', 'NOV', 'CC', 'TALO', 'FHB', 'CAR', 'RDNT', 'APAM', 'BC', 'YELP']\n"
     ]
    }
   ],
   "source": [
    "# return explode_list of Symbols\n",
    "explode_list = explode_df['Symbol'].tolist()\n",
    "\n",
    "\n",
    "print(len(smash_df))\n",
    "print()\n",
    "\n",
    "print(len(explode_df))\n",
    "print(len(explode_list))\n",
    "print(explode_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #3 - SCREENER |\n",
    "|-|\n",
    "| xxx |\n",
    "\n",
    "could think about doing additional available (but separate now) on the subset, additional technical indicators from ta library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LEVEL #4,#5,#6 - SCREENER |\n",
    "|-|\n",
    "| (mini) tight screeners - (toggle on and off w/comments?) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return index data for relevant?\n",
    "good time to see if that chart works opensource similar to tradingview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "could also plot historical data for 53 stocks who cares. check it out on same chart?\n",
    "watch a youtube\n",
    "restart as new feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Notes |\n",
    "|-|\n",
    "| END of WORKING CODE |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read data file from TradingView to pandas df\n",
    "# \"\"\" \n",
    "# Market : US\n",
    "# Exchange : NASDAQ, NYSE\n",
    "# Pre-market Chg > $0.00 USD\n",
    "\n",
    "# Stocks = ~1100\n",
    "# \"\"\"\n",
    "# base_file_path = '/Users/sudz4/Desktop/SPS_local/sps/x_pre_market_gap_up_screener/'\n",
    "# file_name =  'tv_screen_gap-up_2024-10-29.csv'\n",
    "# pmgus_df = pd.read_csv(base_file_path + file_name)\n",
    "\n",
    "\n",
    "# print(len(pmgus_df))\n",
    "# pmgus_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorize_market_cap(df):\n",
    "#     \"\"\"Categorize stocks based on market capitalization.\"\"\"\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'], errors='coerce')\n",
    "#     conditions = [\n",
    "#         (df['Market capitalization'] >= 200_000_000_000),  # Titans\n",
    "#         (df['Market capitalization'] >= 10_000_000_000) & (df['Market capitalization'] < 200_000_000_000),  # Large caps\n",
    "#         (df['Market capitalization'] >= 2_000_000_000) & (df['Market capitalization'] < 10_000_000_000),  # Mid caps\n",
    "#         (df['Market capitalization'] >= 300_000_000) & (df['Market capitalization'] < 2_000_000_000),  # Small caps\n",
    "#         (df['Market capitalization'] > 50_000_000) & (df['Market capitalization'] < 300_000_000),  # Micro caps\n",
    "#         (df['Market capitalization'] <= 50_000_000)  # Shrimp\n",
    "#     ]\n",
    "#     categories = ['Titans', 'Large caps', 'Mid caps', 'Small caps', 'Micro caps', 'Shrimp']\n",
    "#     df['marketCapType'] = np.select(conditions, categories, default='Undefined')\n",
    "#     # drop Undefined\n",
    "#     df = df[df['marketCapType'] != 'Undefined']\n",
    "#     # convert to numeric the Market capitalization column\n",
    "#     df['Market capitalization'] = pd.to_numeric(df['Market capitalization'])\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - categorize market cap\n",
    "# pmgus_df = categorize_market_cap(pmgus_df).copy()\n",
    "# print(len(pmgus_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert necessary columns to numeric\n",
    "# def convert_columns_to_numeric(df, columns):\n",
    "#     \"\"\"Convert specified columns to numeric types.\"\"\"\n",
    "#     for col in columns:\n",
    "#         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "#     return df\n",
    "\n",
    "# # list of columns to convert\n",
    "# numeric_columns = [\n",
    "#     'Market capitalization', 'Float shares outstanding', 'Relative Volume 1 day',\n",
    "#     'Relative Volume at Time', 'Pre-market Change %', 'Pre-market Gap %',\n",
    "#     'Price', 'Volume Weighted Average Price 1 day', 'Volatility 1 day',\n",
    "#     'Volatility 1 week', 'Volatility 1 month', 'Pre-market Volume'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # APPLY - convert columns to numeric\n",
    "# pmgus_df = convert_columns_to_numeric(pmgus_df, numeric_columns).copy()\n",
    "# print(len(pmgus_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Criteria configuration for each market cap category\n",
    "# criteria_config = {\n",
    "#     \"Titans\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.002,  # 0.2% for Titans\n",
    "#         \"float_shares_outstanding_threshold\": 1_000_000_000,  # 1 billion shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.03,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.001,  # 0.1%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.003,  # 0.3% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50_000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.005,  # 0.5% for Large caps\n",
    "#         \"float_shares_outstanding_threshold\": 200000000,  # 200 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,  # More inclusive\n",
    "#         \"relative_volume_at_time_threshold\": 0.04,  # More inclusive\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.005,  # 0.5%\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.004,  # 0.4% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     # \"Midlers\" in TradingView\n",
    "#     \"Midlers\": { \n",
    "#         \"pre_market_change_pct_threshold\": 0.02,  # 2% for Midlers \n",
    "#         \"float_shares_outstanding_threshold\": 50000000,  # 50 million shares\n",
    "#         \"relative_volume_threshold\": 1.3,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.02,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.005,  # 0.5% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.03,  # 3% for Small caps\n",
    "#         \"float_shares_outstanding_threshold\": 20000000,  # 20 million shares\n",
    "#         \"relative_volume_threshold\": 1.2,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.03,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.006,  # 0.6% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.04,  # 4% for Micro caps\n",
    "#         \"float_shares_outstanding_threshold\": 5000000,  # 5 million shares\n",
    "#         \"relative_volume_threshold\": 1.1,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.04,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.007,  # 0.7% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"pre_market_change_pct_threshold\": 0.05,  # 5% for Shrimp\n",
    "#         \"float_shares_outstanding_threshold\": 1000000,  # 1 million shares\n",
    "#         \"relative_volume_threshold\": 1.0,\n",
    "#         \"relative_volume_at_time_threshold\": 0.05,\n",
    "#         \"pre_market_gap_percentage_threshold\": 0.05,\n",
    "#         \"pre_market_vwap_drawdown_threshold\": 0.008, # 0.8% drawdown from VWAP\n",
    "#         \"pre_market_volume_threshold\": 50000  # Minimum pre-market volume\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_stocks(df, config):\n",
    "#     \"\"\"Filter stocks based on configuration criteria.\"\"\"\n",
    "#     conditions = (\n",
    "#         (df['Pre-market Change %'] >= config.get('pre_market_change_pct_threshold', 0)) &\n",
    "#         (df['Float shares outstanding'] <= config.get('float_shares_outstanding_threshold', float('inf'))) &\n",
    "#         (df['Relative Volume 1 day'] >= config.get('relative_volume_threshold', 0)) &\n",
    "#         (df['Relative Volume at Time'] >= config.get('relative_volume_at_time_threshold', 0)) &\n",
    "#         (df['Pre-market Gap %'] >= config.get('pre_market_gap_percentage_threshold', 0)) &\n",
    "#         (df['Price'] >= df['Volume Weighted Average Price 1 day'] * (1 - config.get('pre_market_vwap_drawdown_threshold', 0))) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 day'] >= df['Volatility 1 month']) &\n",
    "#         (df['Pre-market Volume'] >= config.get('pre_market_volume_threshold', 0))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# def screen_stocks_by_category(df, category):\n",
    "#     \"\"\"Filter stocks in a category using predefined criteria.\"\"\"\n",
    "#     config = criteria_config.get(category, {})\n",
    "#     filtered_df = filter_stocks(df, config)\n",
    "#     return filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for category in pmgus_df['marketCapType'].unique():\n",
    "#     category_df = pmgus_df[pmgus_df['marketCapType'] == category]\n",
    "#     gap_up_stage_df = screen_stocks_by_category(category_df, category)\n",
    "#     pmgus_two_df = pd.concat([category_df, gap_up_stage_df], ignore_index=True)\n",
    "\n",
    "# print(len(pmgus_two_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enhanced volume screening -L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_cap_volume_thresholds = {\n",
    "#     \"Titans\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.001,  # 0.1% of ADV minimum in pre-market\n",
    "#         \"min_rel_vol_5min\": 1.5,        # 50% above normal 5-min volume\n",
    "#         \"min_rel_vol_15min\": 1.3        # 30% above normal 15-min volume\n",
    "#     },\n",
    "#     \"Large caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.002,  # 0.2% of ADV\n",
    "#         \"min_rel_vol_5min\": 1.8,\n",
    "#         \"min_rel_vol_15min\": 1.5\n",
    "#     },\n",
    "#     \"Midlers\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.003,  # 0.3% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.0,\n",
    "#         \"min_rel_vol_15min\": 1.7\n",
    "#     },\n",
    "#     \"Small caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.004,  # 0.4% of ADV\n",
    "#         \"min_rel_vol_5min\": 2.5,\n",
    "#         \"min_rel_vol_15min\": 2.0\n",
    "#     },\n",
    "#     \"Micro caps\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.005,  # 0.5% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.0,\n",
    "#         \"min_rel_vol_15min\": 2.5\n",
    "#     },\n",
    "#     \"Shrimp\": {\n",
    "#         \"min_pm_volume_vs_adv\": 0.008,  # 0.8% of ADV\n",
    "#         \"min_rel_vol_5min\": 3.5,\n",
    "#         \"min_rel_vol_15min\": 3.0\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# def analyze_premarket_volume_by_cap(df, conditions):\n",
    "#     \"\"\"\n",
    "#     Enhanced volume analysis based on market cap category with progressive thresholds\n",
    "#     \"\"\"\n",
    "#     df['PM_Volume_Ratio'] = df['Pre-market Volume'] / df['Average Volume 10 days']\n",
    "#     df['Volume_Acceleration'] = df['Relative Volume 5 minutes'] / df['Relative Volume 15 minutes']\n",
    "    \n",
    "#     # Apply filters based on market cap category\n",
    "#     conditions = []\n",
    "#     for cap_type, thresholds in market_cap_volume_thresholds.items():\n",
    "#         cap_condition = (\n",
    "#             (df['marketCapType'] == cap_type) &\n",
    "#             (df['PM_Volume_Ratio'] >= thresholds['min_pm_volume_vs_adv']) &\n",
    "#             (df['Relative Volume 5 minutes'] >= thresholds['min_rel_vol_5min']) &\n",
    "#             (df['Relative Volume 15 minutes'] >= thresholds['min_rel_vol_15min'])\n",
    "#         )\n",
    "#         conditions.append(cap_condition)\n",
    "    \n",
    "#     return pd.concat([df[cond] for cond in conditions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show all pandas row width\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# # show all pandas column width\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmgus_two_df = analyze_premarket_volume_by_cap(pmgus_two_df, market_cap_volume_thresholds)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))\n",
    "# display(pmgus_two_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# new_pmgus_df.to_csv(base_file_path + 'new_pmgus_2024-10-29_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))\n",
    "# print(len(pmgus_two_df.columns))\n",
    "# print(pmgus_two_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final L1 FILTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define no negatives\n",
    "# def no_negatives(df):\n",
    "#     \"\"\"Remove negative values in the data frame.\"\"\"\n",
    "#     return df[(df['Pre-market Change %'] >= 0) & (df['Pre-market Gap %'] >= 0)]\n",
    "\n",
    "# # apply no negatives\n",
    "# pmgus_two_df = no_negatives(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def technical_price_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter stocks based on their position relative to key technical levels\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price near recent highs suggesting momentum\n",
    "#         (df['Price'] >= df['High 1 month'] * 0.85) |  \n",
    "        \n",
    "#         # Price above all major SMAs showing strength\n",
    "#         (df['Price'] > df['Simple Moving Average (5) 1 minute']) &\n",
    "#         (df['Price'] > df['Simple Moving Average (13) 5 minutes']) &\n",
    "        \n",
    "#         # Price near upper Bollinger Band suggesting strength\n",
    "#         (df['Price'] >= df['Bollinger Bands (20) 5 minutes, Basis'])\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply technical price filter\n",
    "# pmgus_two_df = technical_price_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "might need to back off a little on the volatility filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fundamental_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter using analyst ratings and price targets\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Price well below analyst targets suggesting upside\n",
    "#         (df['Target price 1 year'] > df['Price'] * 1.2) &\n",
    "        \n",
    "#         # Strong analyst ratings\n",
    "#         (df['Analyst Rating'].isin(['Strong buy', 'Buy']))\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply fundamental filter\n",
    "# pmgus_two_df = fundamental_filter(pmgus_two_df)\n",
    "\n",
    "# # sort by change percentage descending\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def volatility_filter(df):\n",
    "#     \"\"\"\n",
    "#     Filter for stocks showing increasing volatility\n",
    "#     \"\"\"\n",
    "#     conditions = (\n",
    "#         # Increasing volatility pattern\n",
    "#         (df['Volatility 1 day'] > df['Volatility 1 week']) &\n",
    "#         (df['Volatility 1 week'] > df['Volatility 1 month']) &\n",
    "        \n",
    "#         # Beta filter for more responsive stocks\n",
    "#         (df['Beta 1 year'] > 1.0)\n",
    "#     )\n",
    "#     return df[conditions]\n",
    "\n",
    "# # apply volatility filter\n",
    "# pmgus_two_df = volatility_filter(pmgus_two_df)\n",
    "# print(len(pmgus_two_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sort by largest change percentage\n",
    "# pmgus_two_df.sort_values('Pre-market Change %', ascending=False, inplace=True)\n",
    "\n",
    "# # look at data after initial filters\n",
    "# print(len(pmgus_two_df))\n",
    "# # display(pmgus_two_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # return symbol and price and analyst rating\n",
    "# pmgus_two_df[['Symbol', 'Price', 'Analyst Rating', 'marketCapType']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL GRANULAR FILTERS (when needed?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want another volume one slightly more granular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Price above short-term moving averages indicating immediate strength\n",
    "# price_conditions = (\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (5) 1 minute']) &\n",
    "#     (pmgus_two_df['Price'] > pmgus_two_df['Simple Moving Average (8) 1 minute'])\n",
    "# )\n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[price_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Volume additioal acceleration\n",
    "# vol_addtl_accel_conditions = (\n",
    "#     (pmgus_two_df['Relative Volume 1 minute'] > pmgus_two_df['Relative Volume 5 minutes']) &\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > 1.5)  &  # Strong recent volume\n",
    "#     (pmgus_two_df['Relative Volume 5 minutes'] > pmgus_two_df['Relative Volume 15 minutes']) &  # Accelerating volume\n",
    "#     (pmgus_two_df['Relative Volume 15 minutes'] > pmgus_two_df['Relative Volume 30 minutes'])) # building momentum \n",
    "\n",
    "# # Apply the conditions to filter the dataframe\n",
    "# pmgus_three_df = pmgus_two_df[vol_addtl_accel_conditions]\n",
    "\n",
    "# #3\n",
    "# print(len(pmgus_three_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of additional filters when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open source tradingview type chart view. \n",
    "# then use historical data and plat the daily for the Symbols in the final_pmgus_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sps_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
